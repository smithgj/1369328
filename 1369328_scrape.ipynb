{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "\n",
    "driver.get('http://www.findpeoplesearch.com/')\n",
    " # click Expand Form button\n",
    "# the [0] is there because find_elements_by_id returns a list\n",
    "expand_form_button = driver.find_elements_by_id(\"more-btn\")[0]\n",
    "expand_form_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <input type=\"text\" name=\"full_name\" id=\"full_name\"\n",
    "driver.wait = WebDriverWait(driver, 10)\n",
    "full_name_tbox = driver.wait.until(EC.presence_of_element_located((By.NAME, \"full_name\")))\n",
    "full_name_tbox.send_keys('Marty Owings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No results found\n",
      "Elapsed time = 23.90494132041931\n"
     ]
    }
   ],
   "source": [
    "#<button type=\"submit\" class=\"btn btn-success btn-lg\" id=\"button-search\" style=\"width: 75%\">Search</button>\n",
    "search_button = driver.find_element_by_id(\"button-search\")\n",
    "search_button.send_keys(Keys.ENTER)\n",
    "# wait for  <div class=\"alert alert-info col-md-8\"><h4>Search Results for...</h4>\n",
    "start_time = time.time()\n",
    "driver.wait = WebDriverWait(driver, 20)\n",
    "try:\n",
    "    page_loaded = driver.wait.until(EC.presence_of_element_located((By.ID, \"new-search2\")))\n",
    "except TimeoutException:\n",
    "    try:\n",
    "        soup = BeautifulSoup(driver.page_source, \"html5lib\")\n",
    "        no_results = soup.findAll(\"div\", class_=\"panel panel-primary\")\n",
    "        print(\"No results found\")\n",
    "        driver.quit()\n",
    "    except NoSuchElementException:\n",
    "        print(\"Something went wrong.\")\n",
    "        driver.quit()   \n",
    "    \n",
    "    \n",
    "end_time = time.time()\n",
    "print('Elapsed time = '+ str(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, \"html5lib\")\n",
    "soups = []\n",
    "soups.append(soup)\n",
    "more_pages = True\n",
    "while (more_pages):\n",
    "\n",
    "    next_page = driver.find_element_by_xpath('//*[@id=\"search-results\"]/div[4]/div/nav/ul/li[5]/a')\n",
    "    next_page.send_keys(Keys.ENTER)\n",
    "    start_time = time.time()\n",
    "    driver.wait = WebDriverWait(driver, 20)\n",
    "    page_loaded = driver.wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"search-results\"]/div[4]/div/nav/ul/li[5]/a')))\n",
    "    end_time = time.time()\n",
    "    print('Elapsed time = '+ str(end_time - start_time))\n",
    "    soup = BeautifulSoup(driver.page_source, \"html5lib\")\n",
    "    soups.append(soup)\n",
    "    try:\n",
    "        last_page = driver.find_element_by_css_selector('li.next-page.disabled')\n",
    "        #search-results > div:nth-child(6) > div > nav > ul > li.next-page.disabled\n",
    "        more_pages = False\n",
    "        break\n",
    "    except NoSuchElementException:    \n",
    "        more_pages = True\n",
    "print (str(len(soups)) + ' pages scraped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get all col-md-4 from all pages (from each soup in soups)\n",
    "people = []\n",
    "for soup in soups:\n",
    "#    cols=soup.findAll(\"div\",class_=\"col-md-4\")\n",
    "    cols=soup.findAll(\"div\", class_=\"panel panel-primary\")\n",
    "    for i in range (0, len(cols)):\n",
    "        people.append(cols[i])\n",
    "print('number of persons found = ' + str(len(people)))\n",
    "\n",
    "#todo loop through people[] and get data:\n",
    "for z in range(0, len(people)):\n",
    "    one_person = people[z]\n",
    "    tags = one_person.findAll('li')\n",
    "\n",
    "    data_headers = one_person.findAll('span', class_='data_header')\n",
    "    data_header_names = []\n",
    "    for i in range(0, len(data_headers)):\n",
    "        data_header_names.append(data_headers[i].text.split())\n",
    "    print (data_header_names) \n",
    "    num_of_addresses = 0\n",
    "    num_of_phones = 0\n",
    "    num_of_emails = 0\n",
    "    for i in range (0, len(data_header_names)):\n",
    "        if data_header_names[i][1] == 'Street':\n",
    "            num_of_addresses = int(data_header_names[i][0])\n",
    "        elif data_header_names[i][1] == 'Phone':\n",
    "            num_of_phones = int(data_header_names[i][0])\n",
    "        elif data_header_names[i][1] == 'Email':\n",
    "            num_of_emails = int(data_header_names[i][0])\n",
    "\n",
    "    print('Addresses=' + str(num_of_addresses) + '  Phones=' + str(num_of_phones) + '  Emails=' + str(num_of_emails))    \n",
    "\n",
    "    for i in range(0, num_of_addresses):\n",
    "        addy_data = str(tags[i])\n",
    "        begin = addy_data.find('data-person=\"')+13\n",
    "        end = addy_data.find('\" data-person-address')\n",
    "        addy_data_1 = addy_data[begin:end]\n",
    "        print (addy_data_1)\n",
    "\n",
    "    for j in range(num_of_addresses, num_of_addresses + num_of_phones):\n",
    "        phone_data = str(tags[j])\n",
    "        begin = phone_data.find('<b>Phone number: </b>') + 21\n",
    "        end = phone_data.find('<br/><b>Company:')\n",
    "        phone_data_1 = phone_data[begin:end]\n",
    "        print (phone_data_1)\n",
    "\n",
    "    for j in range(num_of_addresses + num_of_phones, num_of_addresses + num_of_phones + num_of_emails):\n",
    "        email_data = str(tags[j])\n",
    "        begin = email_data.find('<a href=\"mailto:') + 17\n",
    "        end = email_data.find('\">')\n",
    "        email_data_1 = email_data[begin:end]\n",
    "        print (email_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
